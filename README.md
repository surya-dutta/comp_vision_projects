Computer Vision Projects 2023 - 2024

Project 1 - Comparative Analysis of Multi-Layer Perceptrons and Convolutional Neural Networks on CIFAR-10

  Developed and trained both Multi-Layer Perceptrons (MLPs) and Convolutional Neural Networks (ConvNets) to perform image classification on the CIFAR-10 dataset using Python and PyTorch.
  Evaluated model performance by testing various regularization techniques, including dropout and weight decay, to prevent overfitting and enhance generalization.
  Conducted a detailed comparison between MLPs and ConvNets, highlighting the superior ability of ConvNets to capture spatial hierarchies in image data.
  Investigated the potential risks of noise overfitting in neural networks, providing insights into the robustness of different architectures against noisy data.
  Utilized PyTorch's deep learning libraries to implement and experiment with different neural network architectures, achieving a deeper understanding of model performance and limitations.

Project 2 - Vision Transformers (ViT) on CIFAR-10 Dataset

  Implemented Vision Transformers (ViT) for image classification on the CIFAR-10 dataset using PyTorch and PyTorch Lightning.
  Leveraged PyTorch Lightning to streamline model training, monitoring, and checkpointing, ensuring efficient and reproducible results.
  Applied advanced techniques in deep learning, such as meta-transformers, to enhance model accuracy.
  Conducted comprehensive experiments to analyze the performance of Vision Transformers on standard image datasets, and visualized the results using Matplotlib and Seaborn.
  Tracked model training progress and metrics using TensorBoard, facilitating detailed performance analysis and model tuning.

Project 3 - Enhancing Image Classification with Self-Supervised Learning

Implemented and compared self-supervised learning models, specifically SimCLR and Barlow Twins, using PyTorch and PyTorch Lightning to enhance feature extraction and classification accuracy on the STL10 dataset without relying on labeled data. Achieved superior model performance by applying advanced data augmentation and contrastive loss techniques, resulting in significant improvements in test accuracy and generalization compared to traditional supervised methods.

  
